{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scattering Net + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from matplotlib import cm\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from kymatio import Scattering2D\n",
    "from kymatio import HarmonicScattering3D\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "flip_axes = lambda tens: tens.permute(1, 2, 0)\n",
    "semicond_dataset = datasets.ImageFolder(root='/home/sutd/Documents/Workplace/DLCourse/MATH6380P/semi/train/train_contest', \n",
    "                                        transform=transforms.Compose(\n",
    "                                            [\n",
    "                                                transforms.CenterCrop((260,260)),\n",
    "                                                transforms.ToTensor()\n",
    "                                            ]\n",
    "                                        )\n",
    "                                       )\n",
    "dataset_loader = torch.utils.data.DataLoader(semicond_dataset,\n",
    "                                             batch_size=16, shuffle=True,\n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        inp = std * inp + mean\n",
    "        \n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp, interpolation=\"bilinear\", cmap=cm.RdYlGn, aspect=\"auto\")\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id, (features, labels) = next(enumerate(dataset_loader))\n",
    "len(dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_grid = torchvision.utils.make_grid(features, nrow=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(feature_grid, title=[x for x in labels], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader_new = torch.utils.data.DataLoader(semicond_dataset,\n",
    "                                                batch_size=100, shuffle=True,\n",
    "                                                num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id, (features, labels) = next(enumerate(dataset_loader_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "times = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scattering = HarmonicScattering3D(J=2, shape=(features.shape[1], features.shape[2], features.shape[3]), L=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "scattering.cuda()\n",
    "features = features.cuda()\n",
    "\n",
    "for _ in range(times):\n",
    "    scattering(features)\n",
    "    \n",
    "torch.cuda.synchronize()\n",
    "\n",
    "t_elapsed = time.time() - t_start\n",
    "\n",
    "fmt_str = 'Elapsed time: {:2f} [s / {:d} evals], avg: {:.2f} (s/batch)'\n",
    "print(fmt_str.format(t_elapsed, times, t_elapsed/times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(scattering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction using Scattering Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(semicond_dataset, batch_size=100, shuffle=True, num_workers=10)\n",
    "scattering = HarmonicScattering3D(J=2, shape=(features.shape[1], features.shape[2], features.shape[3]), L=2)\n",
    "scattering.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coll = []\n",
    "label_coll = []\n",
    "save_to_disk = True\n",
    "train = True\n",
    "\n",
    "for batch_id, [features, labels] in enumerate(dataloader):\n",
    "    # sample is a list with the first element corresponding to the images\n",
    "    print(\"Batch {}, features shape: {}, labels shape: {}\".format(batch_id, features.shape, labels.shape))\n",
    "    features = features.cuda()\n",
    "\n",
    "    t1 = time.time()\n",
    "    out = scattering(features)\n",
    "    t2 = time.time()\n",
    "    print(\"Output shape: {}, Time taken: {}\".format(out.shape, t2 - t1))\n",
    "\n",
    "    # move output, features and labels back to the CPU to prevent a memory leak and release memory from GPU\n",
    "    out = out.to(\"cpu\")\n",
    "    features = features.to(\"cpu\")\n",
    "    # do not need to move labels to GPU because we are not doing any computation on them\n",
    "    # labels = labels.to(\"cpu\")\n",
    "\n",
    "    out = torch.flatten(out, start_dim=1)\n",
    "    print(\"Flattend output shape: {}\".format(out.shape))\n",
    "\n",
    "    feat_coll.append(out)\n",
    "    label_coll.append(labels)\n",
    "\n",
    "out_features = torch.flatten(torch.stack(feat_coll), start_dim=0, end_dim=1)\n",
    "out_labels = torch.flatten(torch.stack(label_coll), start_dim=0, end_dim=1)\n",
    "\n",
    "print(\"The final features matrix has shape: {}\".format(out_features.shape))\n",
    "\n",
    "if save_to_disk:\n",
    "    # save as TensorDataset\n",
    "    out_dataset = TensorDataset(out_features, out_labels)\n",
    "    if train:\n",
    "        prefix = \"train\"\n",
    "    else:\n",
    "        prefix = \"test\"\n",
    "    filename = \"{}_{}_dataset.pt\".format(prefix, scattering.__class__.__name__)\n",
    "    torch.save(out_dataset, filename)\n",
    "    print(\"Saved features at {}/{}\".format(os.getcwd(), filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stored_dataset(filename, train=True): \n",
    "    loaded_dataset = torch.load(filename)\n",
    "    features = loaded_dataset[:][0]\n",
    "    labels = loaded_dataset[:][1]\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train_HarmonicScatteringTorch3D_dataset.pt\"\n",
    "out_features, out_labels = get_stored_dataset(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = out_labels.numpy()\n",
    "features = out_features.numpy()\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, counts = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_label_counts = sum([1 for i in range(len(labels)) if labels[i] == 1])\n",
    "neg_label_counts = sum([1 for i in range(len(labels)) if labels[i] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weights = neg_label_counts/pos_label_counts\n",
    "scale_pos_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"params = {}\n",
    "params[\"objective\"] = \"binary:logistic\"\n",
    "params[\"verbosity\"] = 2\n",
    "params[\"gamma\"] = 10\n",
    "params[\"max_depth\"] = 4\n",
    "params[\"subsample\"] = 0.5\n",
    "params[\"colsample_bytree\"] = 0.5\n",
    "params[\"colsample_bylevel\"] = 0.5\n",
    "params[\"colsample_bynode\"] = 0.5\n",
    "params[\"tree_method\"] = \"gpu_hist\"\n",
    "params[\"scale_pos_weight\"] = scale_pos_weights\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn APOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    max_depth = 3, \n",
    "    learning_rate = 0.1, \n",
    "    n_estimators = 100, \n",
    "    verbosity = 2, \n",
    "    objective = \"binary:logistic\",\n",
    "    booster = \"gbtree\",\n",
    "    tree_method = \"gpu_hist\",\n",
    "    gamma = 10,\n",
    "    subsample = 0.5,\n",
    "    colsample_bytree = 0.5,\n",
    "    colsample_bylevel = 0.5,\n",
    "    colsample_bynode = 0.5,\n",
    "    scale_pos_weight = scale_pos_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = xgb_model.fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.callback import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataLoaders.from_folder(\"/home/sutd/Documents/Workplace/DLCourse/MATH6380P/semi/train/train_contest\", item_tfms=Resize(260), valid_pct=0.2, batch_tfms=Normalize.from_stats(*imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = cnn_learner(\n",
    "    data, \n",
    "    models.resnet34, \n",
    "    metrics=[error_rate]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# learner.fine_tune(1)\n",
    "\n",
    "learner.lr_find()\n",
    "learner.fine_tune(2, 3e-3)\n",
    "\n",
    "learner.save('test_model')\n",
    "\n",
    "interp = ClassificationInterpretation.from_learner(learner)\n",
    "\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(10, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = ImageDataLoaders.from_folder(\"/home/sutd/Documents/Workplace/DLCourse/MATH6380P/semi/train/train_contest\", item_tfms=Resize(260), valid_pct=0.2, batch_tfms=Normalize.from_stats(*imagenet_stats))\n",
    "\n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for img,target in data_new.train_ds:\n",
    "    labels.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labels))\n",
    "labels = torch.stack(labels)\n",
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of items in the dataset for each label?\n",
    "\"\"\"\n",
    "train_labels = data_new.train_dl.dataset.y.items\n",
    "_, counts    = np.unique(train_labels,return_counts=True)\n",
    "\n",
    "print(counts, train_labels)\n",
    "type(counts)\n",
    "\n",
    "1./counts\n",
    "\n",
    "class_weights = 1./counts\n",
    "weights       = class_weights[train_labels]\n",
    "\n",
    "type(class_weights)\n",
    "\n",
    "label_counts = np.bincount([data_new.train_dl.dataset.y[i].data for i in range(len(data_new.train_dl.dataset))])\n",
    "\n",
    "label_counts\n",
    "\n",
    "total_len_oversample = int(data_new.c*np.max(label_counts)) #WHY????\n",
    "\n",
    "print(type(total_len_oversample), total_len_oversample)\n",
    "\"\"\"\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(\n",
    "    data_new, \n",
    "    models.resnet18, \n",
    "    metrics=[error_rate]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(25, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"resnet18_25ep_oversampling_no_transforms.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10,2.5e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "interp.plot_confusion_matrix()\n",
    "interp.plot_top_losses(10, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ImageDataBunch.from_folder(\"/home/sutd/Documents/Workplace/DLCourse/MATH6380P/semi/test/test_contest\", test=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(\n",
    "    do_flip = True, \n",
    "    flip_vert = True, \n",
    "    max_rotate = None,\n",
    "    max_warp = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ex(): return open_image('/home/sutd/Documents/Workplace/DLCourse/MATH6380P/semi/train/train_contest/good_all/WEA938001D1A_10-5CW-ITISA49-1_78_2.bmp')\n",
    "\n",
    "def plots_f(rows, cols, width, height, **kwargs):\n",
    "    [get_ex().apply_tfms(tfms[0], **kwargs).show(ax=ax) for i,ax in enumerate(plt.subplots(\n",
    "        rows,cols,figsize=(width,height))[1].flatten())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_f(2, 4, 12, 6, size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed = ImageDataBunch.from_folder(\"/home/sutd/Documents/Workplace/DLCourse/MATH6380P/semi/train/train_contest\", \n",
    "                                              valid_pct=0.2, ds_tfms = tfms).normalize(imagenet_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2 = cnn_learner(\n",
    "    data_transformed, \n",
    "    models.resnet18, \n",
    "    metrics=[error_rate], \n",
    "    opt_func = optim.Adam\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    callbacks.OverSamplingCallback(learn2),\n",
    "    callbacks.ReduceLROnPlateauCallback(learn2, monitor=\"valid_loss\", mode=\"auto\", patience=3, min_delta=0.01),\n",
    "    callbacks.SaveModelCallback(\n",
    "        learn2, \n",
    "        monitor=\"error_rate\", \n",
    "        mode=\"min\", \n",
    "        every=\"improvement\", \n",
    "        name=\"transformed_best\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.lr_find()\n",
    "learn2.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.fit_one_cycle(5, max_lr=slice(3e-5, 4e-3), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.unfreeze()\n",
    "learn2.lr_find()\n",
    "learn2.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn2.fit(5, slice(3e-6, 6e-5), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    OverSamplingCallback(learn2),\n",
    "    ReduceLROnPlateauCallback(learn2, monitor=\"valid_loss\", mode=\"auto\", patience=3, min_delta=0.01),\n",
    "    SaveModelCallback(\n",
    "        learn2, \n",
    "        monitor=\"error_rate\", \n",
    "        mode=\"min\", \n",
    "        every=\"improvement\", \n",
    "        name=\"tsfmd_best_attempt_2\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn2.fit(5, slice(3e-6, 6e-5), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    OverSamplingCallback(learn2),\n",
    "    ReduceLROnPlateauCallback(learn2, monitor=\"valid_loss\", mode=\"auto\", patience=3, min_delta=0.01),\n",
    "    SaveModelCallback(\n",
    "        learn2, \n",
    "        monitor=\"error_rate\", \n",
    "        mode=\"min\", \n",
    "        every=\"epoch\", \n",
    "        name=\"tsfmd_best_attempt_3\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.fit(5, slice(3e-6, 6e-5), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    OverSamplingCallback(learn2),\n",
    "    ReduceLROnPlateauCallback(learn2, monitor=\"error_rate\", mode=\"auto\", patience=2, min_delta=0.001),\n",
    "    SaveModelCallback(\n",
    "        learn2, \n",
    "        monitor=\"error_rate\", \n",
    "        mode=\"min\", \n",
    "        every=\"epoch\", \n",
    "        name=\"tsfmd_best_attempt_4\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn2.fit(5, slice(3e-6, 6e-5), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed.train_dl.dl.num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    OverSamplingCallback(learn2),\n",
    "    ReduceLROnPlateauCallback(learn2, monitor=\"error_rate\", mode=\"auto\", patience=2, min_delta=0.001),\n",
    "    SaveModelCallback(\n",
    "        learn2, \n",
    "        monitor=\"error_rate\", \n",
    "        mode=\"min\", \n",
    "        every=\"epoch\", \n",
    "        name=\"tsfmd_best_attempt_5\"\n",
    "    ),\n",
    "    ShowGraph(learn2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.load(\"tsfmd_best_attempt_5_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    OverSamplingCallback(learn2),\n",
    "    ReduceLROnPlateauCallback(learn2, monitor=\"error_rate\", mode=\"auto\", patience=2, min_delta=0.001),\n",
    "    SaveModelCallback(\n",
    "        learn2, \n",
    "        monitor=\"error_rate\", \n",
    "        mode=\"min\", \n",
    "        every=\"epoch\", \n",
    "        name=\"tsfmd_best_attempt_6\"\n",
    "    ),\n",
    "    ShowGraph(learn2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.fit(5, slice(1e-6, 6e-5), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    OverSamplingCallback(learn2),\n",
    "    ReduceLROnPlateauCallback(learn2, monitor=\"valid_loss\", mode=\"auto\", patience=2, min_delta=0.001),\n",
    "    SaveModelCallback(\n",
    "        learn2, \n",
    "        monitor=\"error_rate\", \n",
    "        mode=\"min\", \n",
    "        every=\"epoch\", \n",
    "        name=\"tsfmd_best_attempt_7\"\n",
    "    ),\n",
    "    ShowGraph(learn2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.fit(5, slice(1e-6, 6e-5), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    OverSamplingCallback(learn2),\n",
    "    ReduceLROnPlateauCallback(learn2, monitor=\"valid_loss\", mode=\"auto\", patience=2, min_delta=0.001),\n",
    "    SaveModelCallback(\n",
    "        learn2, \n",
    "        monitor=\"error_rate\", \n",
    "        mode=\"min\", \n",
    "        every=\"epoch\", \n",
    "        name=\"tsfmd_best_attempt_8\"\n",
    "    ),\n",
    "    ShowGraph(learn2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn2.fit(5, slice(1e-6, 6e-5), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    OverSamplingCallback(learn2),\n",
    "    ReduceLROnPlateauCallback(learn2, monitor=\"valid_loss\", mode=\"auto\", patience=2, min_delta=0.001),\n",
    "    SaveModelCallback(\n",
    "        learn2, \n",
    "        monitor=\"error_rate\", \n",
    "        mode=\"min\", \n",
    "        every=\"epoch\", \n",
    "        name=\"tsfmd_best_attempt_9\"\n",
    "    ),\n",
    "    ShowGraph(learn2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn2.fit(5, slice(1e-6, 6e-5), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    OverSamplingCallback(learn2),\n",
    "    ReduceLROnPlateauCallback(learn2, monitor=\"valid_loss\", mode=\"auto\", patience=2, min_delta=0.001),\n",
    "    SaveModelCallback(\n",
    "        learn2, \n",
    "        monitor=\"error_rate\", \n",
    "        mode=\"min\", \n",
    "        every=\"epoch\", \n",
    "        name=\"tsfmd_best_attempt_11\"\n",
    "    ),\n",
    "    ShowGraph(learn2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.fit(10, slice(1e-6, 6e-5), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2 = cnn_learner(\n",
    "    data_transformed, \n",
    "    models.resnet18, \n",
    "    metrics=[error_rate, AUROC()], \n",
    "    opt_func = optim.Adam\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.load(\"/home/sutd/Documents/Workplace/DLCourse/MATH6380P/project_2/models/tsfmd_best_attempt_9_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    OverSamplingCallback(learn2),\n",
    "    ReduceLROnPlateauCallback(learn2, monitor=\"valid_loss\", mode=\"auto\", patience=2, min_delta=0.001),\n",
    "    SaveModelCallback(\n",
    "        learn2, \n",
    "        monitor=\"error_rate\", \n",
    "        mode=\"min\", \n",
    "        every=\"epoch\", \n",
    "        name=\"tsfmd_best_w_auc_1\"\n",
    "    ),\n",
    "    ShowGraph(learn2),\n",
    "    AUROC()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn2.fit(5, slice(1e-6, 6e-5), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = learn2.TTA()\n",
    "preds[0][:5, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = preds[0][:10, :].numpy(); blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(blah, axis=1); print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed.train_ds.x[4001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn2.predict(data_transformed.train_ds.x[1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed.train_dl.dataset.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp2 = ClassificationInterpretation.from_learner(learn2)\n",
    "\n",
    "interp2.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp2.plot_top_losses(9, heatmap=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageDataLoaders.from_folder(\"/home/sutd/Documents/Workplace/DLCourse/MATH6380P/semi\", train = \"train\", test = \"test\",\n",
    "                                        item_tfms=Resize(260), valid_pct=0.0001, batch_tfms=Normalize.from_stats(*imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_full = cnn_learner(\n",
    "    train_data, \n",
    "    models.resnet18, \n",
    "    metrics=[error_rate]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_full.lr_find()\n",
    "learn_full.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_full.unfreeze()\n",
    "learn_full.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_full.fit(25, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_full.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_full.fit(5, slice(1e-6, 6e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"final_model.pt\"\n",
    "torch.save(learn_full, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_full.save('final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ImageDataLoaders.from_folder(\"/home/sutd/Documents/Workplace/DLCourse/MATH6380P/semi/test/test_contest/test\", \n",
    "                                        item_tfms=Resize(260), valid_pct=0.0001, batch_tfms=Normalize.from_stats(*imagenet_stats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, labels = learn_full.tta(ds_type=DatasetType.Test, scale = 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.test_ds.x[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = list(map(lambda x: str(x).split(\"/\")[-1], train_data.test_ds.x.items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames =  list(map(lambda x: x.split(\".\")[0], paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip(filenames, preds.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(filenames, preds.numpy())), columns = [\"id\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/sutd/Documents/Workplace/DLCourse/MATH6380P/project_2/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
